<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="zh-CN"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://hxf0223.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://hxf0223.github.io/" rel="alternate" type="text/html" hreflang="zh-CN"/><updated>2026-02-27T10:47:14+00:00</updated><id>https://hxf0223.github.io/feed.xml</id><title type="html">blank</title><subtitle>Roderick Huang 的个人博客，记录工作与技术。 </subtitle><entry><title type="html">al-folio 本地部署记录（Ubuntu 24.04）</title><link href="https://hxf0223.github.io/blog/2026/al-folio-local-deploy-ubuntu2404/" rel="alternate" type="text/html" title="al-folio 本地部署记录（Ubuntu 24.04）"/><published>2026-02-27T02:00:00+00:00</published><updated>2026-02-27T02:00:00+00:00</updated><id>https://hxf0223.github.io/blog/2026/al-folio-local-deploy-ubuntu2404</id><content type="html" xml:base="https://hxf0223.github.io/blog/2026/al-folio-local-deploy-ubuntu2404/"><![CDATA[<p>本文记录在 Ubuntu 24.04 上从零开始本地部署 <a href="https://github.com/alshedivat/al-folio">al-folio</a> Jekyll 主题的完整流程，以及遇到的问题和解决方案。</p> <h2 id="环境说明">环境说明</h2> <ul> <li>操作系统：Ubuntu 24.04 x86_64</li> <li>Ruby 版本管理：rbenv</li> <li>目标 Ruby 版本：3.3.5</li> </ul> <hr/> <h2 id="第一步安装系统依赖">第一步：安装系统依赖</h2> <p>Ruby 编译和 Jekyll 运行需要以下系统包：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> libyaml-dev libssl-dev libreadline-dev zlib1g-dev libffi-dev imagemagick nodejs
</code></pre></div></div> <blockquote> <p><strong>说明：</strong></p> <ul> <li><code class="language-plaintext highlighter-rouge">libyaml-dev</code>：编译 Ruby 3.3.x 时必须，缺少会导致 <code class="language-plaintext highlighter-rouge">psych</code> 扩展编译失败。</li> <li><code class="language-plaintext highlighter-rouge">imagemagick</code>：提供 <code class="language-plaintext highlighter-rouge">convert</code> 命令，用于生成响应式 WebP 图片。</li> <li><code class="language-plaintext highlighter-rouge">nodejs</code>：为 Terser JS 压缩插件提供运行时。</li> </ul> </blockquote> <hr/> <h2 id="第二步安装-ruby-335通过-rbenv">第二步：安装 Ruby 3.3.5（通过 rbenv）</h2> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 安装 Ruby 3.3.5</span>
rbenv <span class="nb">install </span>3.3.5

<span class="c"># 在项目目录设置 Ruby 版本</span>
<span class="nb">cd</span> ~/work/hxf0223.github.io
rbenv <span class="nb">local </span>3.3.5

<span class="c"># 验证</span>
ruby <span class="nt">--version</span>
<span class="c"># =&gt; ruby 3.3.5 (2024-09-03 revision ef084cc8f4) [x86_64-linux]</span>
</code></pre></div></div> <blockquote> <p><strong>注意：</strong> 必须先安装 <code class="language-plaintext highlighter-rouge">libyaml-dev</code> 再执行 <code class="language-plaintext highlighter-rouge">rbenv install</code>，否则会报错：</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>*** Following extensions are not compiled:
psych:
    Could not be configured. It will not be installed.
BUILD FAILED
</code></pre></div> </div> </blockquote> <hr/> <h2 id="第三步处理-gem_home-冲突">第三步：处理 GEM_HOME 冲突</h2> <p>若系统 <code class="language-plaintext highlighter-rouge">~/.bashrc</code> 中存在为旧版 Ruby 手动设置的 <code class="language-plaintext highlighter-rouge">GEM_HOME</code>，会导致 gem 版本冲突（<code class="language-plaintext highlighter-rouge">linked to incompatible libruby-3.2.so</code>）。</p> <p>检查并注释掉相关行：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 编辑 ~/.bashrc，注释掉以下两行：</span>
<span class="c"># export GEM_HOME="$HOME/gems"</span>
<span class="c"># export PATH="$HOME/gems/bin:$PATH"</span>
</code></pre></div></div> <p>在新终端生效前，当前终端需手动清除：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">unset </span>GEM_HOME
<span class="nb">unset </span>GEM_PATH
</code></pre></div></div> <hr/> <h2 id="第四步安装-jupyter处理-ipynb-文件">第四步：安装 Jupyter（处理 .ipynb 文件）</h2> <p>al-folio 支持在博文中嵌入 Jupyter Notebook，需要系统安装 <code class="language-plaintext highlighter-rouge">jupyter</code>：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> jupyter-core jupyter-nbconvert
</code></pre></div></div> <blockquote> <p>Ubuntu 24.04 限制了通过 <code class="language-plaintext highlighter-rouge">pip install --user</code> 安装包，建议直接使用 apt 安装。</p> </blockquote> <hr/> <h2 id="第五步安装-ruby-gems">第五步：安装 Ruby Gems</h2> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> ~/work/hxf0223.github.io

<span class="c"># 清除旧的 GEM_HOME（如尚未在新终端中）</span>
<span class="nb">unset </span>GEM_HOME

<span class="c"># 安装 Bundler</span>
gem <span class="nb">install </span>bundler

<span class="c"># 删除旧的 Gemfile.lock（如果存在）</span>
<span class="nb">rm</span> <span class="nt">-f</span> Gemfile.lock

<span class="c"># 安装所有依赖</span>
bundle <span class="nb">install</span>
</code></pre></div></div> <p>成功后输出类似：</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Bundle complete! 27 Gemfile dependencies, 100 gems now installed.
</code></pre></div></div> <hr/> <h2 id="第六步启动本地服务">第六步：启动本地服务</h2> <blockquote> <p><strong>每次打开新终端前</strong>，如果 <code class="language-plaintext highlighter-rouge">~/.bashrc</code> 中的 <code class="language-plaintext highlighter-rouge">GEM_HOME</code> 尚未完全失效（旧终端），需先执行：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">unset </span>GEM_HOME
</code></pre></div> </div> <p>新登录的终端（<code class="language-plaintext highlighter-rouge">.bashrc</code> 已修复后）无需此步骤。</p> </blockquote> <h3 id="常规启动含文件监听推荐开发时使用">常规启动（含文件监听，推荐开发时使用）</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">unset </span>GEM_HOME <span class="o">&amp;&amp;</span> bundle <span class="nb">exec </span>jekyll serve <span class="nt">--port</span> 4000
</code></pre></div></div> <p>访问 <a href="http://localhost:4000">http://localhost:4000</a> 查看效果，修改文件后会自动重新构建。</p> <h3 id="仅构建不启动服务器">仅构建，不启动服务器</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">unset </span>GEM_HOME <span class="o">&amp;&amp;</span> bundle <span class="nb">exec </span>jekyll build
</code></pre></div></div> <p>生成结果输出到 <code class="language-plaintext highlighter-rouge">_site/</code> 目录。</p> <h3 id="增量构建加速二次构建">增量构建（加速二次构建）</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">unset </span>GEM_HOME <span class="o">&amp;&amp;</span> bundle <span class="nb">exec </span>jekyll serve <span class="nt">--port</span> 4000 <span class="nt">--incremental</span>
</code></pre></div></div> <p>只重新编译发生变动的文件，适合文章较多时加速预览。</p> <h3 id="指定-host局域网访问">指定 host（局域网访问）</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">unset </span>GEM_HOME <span class="o">&amp;&amp;</span> bundle <span class="nb">exec </span>jekyll serve <span class="nt">--port</span> 4000 <span class="nt">--host</span> 0.0.0.0
</code></pre></div></div> <p>局域网内其他设备可通过 <code class="language-plaintext highlighter-rouge">http://&lt;本机IP&gt;:4000</code> 访问。</p> <h3 id="生产环境构建">生产环境构建</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">unset </span>GEM_HOME <span class="o">&amp;&amp;</span> <span class="nv">JEKYLL_ENV</span><span class="o">=</span>production bundle <span class="nb">exec </span>jekyll build
</code></pre></div></div> <p>启用 CSS/JS 压缩等生产优化，与 GitHub Actions 部署行为一致。</p> <hr/> <h2 id="常见问题汇总">常见问题汇总</h2> <table> <thead> <tr> <th>错误信息</th> <th>原因</th> <th>解决方案</th> </tr> </thead> <tbody> <tr> <td><code class="language-plaintext highlighter-rouge">psych: Could not be configured. BUILD FAILED</code></td> <td>缺少 <code class="language-plaintext highlighter-rouge">libyaml-dev</code></td> <td><code class="language-plaintext highlighter-rouge">sudo apt-get install libyaml-dev</code></td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">linked to incompatible libruby-3.2.so</code></td> <td><code class="language-plaintext highlighter-rouge">GEM_HOME</code> 指向旧版本 gems</td> <td>注释 <code class="language-plaintext highlighter-rouge">~/.bashrc</code> 中的 <code class="language-plaintext highlighter-rouge">GEM_HOME</code>，执行 <code class="language-plaintext highlighter-rouge">unset GEM_HOME</code></td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">bundler (= 4.0.4) required by user-specified dependency</code></td> <td>Ruby 版本太旧（3.1.x），Bundler 4.x 需要 Ruby &gt;= 3.3</td> <td>升级到 Ruby 3.3.5</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">sh: convert: not found</code></td> <td>ImageMagick 未安装</td> <td><code class="language-plaintext highlighter-rouge">sudo apt-get install imagemagick</code></td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">No such file or directory - jupyter</code></td> <td>jupyter 未安装</td> <td><code class="language-plaintext highlighter-rouge">sudo apt-get install jupyter-core jupyter-nbconvert</code></td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">Could not find a JavaScript runtime</code></td> <td>Node.js 未安装</td> <td><code class="language-plaintext highlighter-rouge">sudo apt-get install nodejs</code></td> </tr> </tbody> </table> <hr/> <h2 id="一键安装脚本">一键安装脚本</h2> <p>将以上步骤整合为脚本，方便在新机器上复现：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nb">set</span> <span class="nt">-e</span>

<span class="c"># 1. 系统依赖</span>
<span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> libyaml-dev libssl-dev libreadline-dev <span class="se">\</span>
    zlib1g-dev libffi-dev imagemagick nodejs <span class="se">\</span>
    jupyter-core jupyter-nbconvert

<span class="c"># 2. 安装 Ruby 3.3.5</span>
rbenv <span class="nb">install </span>3.3.5
rbenv <span class="nb">local </span>3.3.5

<span class="c"># 3. 清除旧 GEM_HOME（如有）</span>
<span class="nb">unset </span>GEM_HOME
<span class="nb">unset </span>GEM_PATH

<span class="c"># 4. 安装 Gems</span>
gem <span class="nb">install </span>bundler
<span class="nb">rm</span> <span class="nt">-f</span> Gemfile.lock
bundle <span class="nb">install

echo</span> <span class="s2">"✅ 完成！执行以下命令启动本地服务："</span>
<span class="nb">echo</span> <span class="s2">"   unset GEM_HOME &amp;&amp; bundle exec jekyll serve --port 4000"</span>
</code></pre></div></div> <hr/> <h2 id="部署到-github-pages-后的-prettier-检查">部署到 GitHub Pages 后的 Prettier 检查</h2> <p>将代码推送到 GitHub 后，Actions 会自动运行 Prettier 格式检查。若出现以下错误，说明文件格式不符合规范：</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Checking formatting...
[warn] _config.yml
[warn] _posts/xxx.md
[warn] Code style issues found in N files. Run Prettier with --write to fix.
</code></pre></div></div> <h3 id="安装-npm如未安装">安装 npm（如未安装）</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> npm
</code></pre></div></div> <h3 id="安装-prettier-及-liquid-插件">安装 Prettier 及 Liquid 插件</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> ~/work/hxf0223.github.io
npm <span class="nb">install</span> <span class="nt">--save-dev</span> prettier @shopify/prettier-plugin-liquid
</code></pre></div></div> <h3 id="修复格式问题">修复格式问题</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>npx prettier <span class="nb">.</span> <span class="nt">--write</span>
</code></pre></div></div> <h3 id="验证全部通过">验证全部通过</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>npx prettier <span class="nb">.</span> <span class="nt">--check</span>
<span class="c"># =&gt; All matched files use Prettier code style!</span>
</code></pre></div></div> <blockquote> <p><strong>建议：</strong> 每次 <code class="language-plaintext highlighter-rouge">git push</code> 之前先运行 <code class="language-plaintext highlighter-rouge">npx prettier . --write</code>，可避免 CI 格式检查失败。</p> </blockquote> <hr/> <h2 id="参考资料">参考资料</h2> <ul> <li><a href="https://george-gca.github.io/blog/2022/running-local-al-folio/">Running local al-folio</a></li> <li><a href="https://zhuanlan.zhihu.com/p/707289907">Jekyll al-folio 博客部署指南</a></li> <li><a href="https://github.com/flammingRaven/flammingRaven.github.io">flammingRaven 的 al-folio 部署参考</a></li> </ul>]]></content><author><name></name></author><category term="工具"/><category term="博客"/><category term="jekyll"/><category term="al-folio"/><category term="ubuntu"/><category term="ruby"/><category term="rbenv"/><summary type="html"><![CDATA[本文记录在 Ubuntu 24.04 上从零开始本地部署 al-folio Jekyll 主题的完整流程，以及遇到的问题和解决方案。]]></summary></entry><entry><title type="html">CUTLASS-Cute 初步(3.1)：TiledCopy 以及 TiledMMA 配置示例</title><link href="https://hxf0223.github.io/blog/2025/Cute%E5%88%9D%E6%AD%A53.1-TileMMA%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/" rel="alternate" type="text/html" title="CUTLASS-Cute 初步(3.1)：TiledCopy 以及 TiledMMA 配置示例"/><published>2025-02-26T00:00:00+00:00</published><updated>2025-02-26T00:00:00+00:00</updated><id>https://hxf0223.github.io/blog/2025/Cute%E5%88%9D%E6%AD%A53.1-TileMMA%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B</id><content type="html" xml:base="https://hxf0223.github.io/blog/2025/Cute%E5%88%9D%E6%AD%A53.1-TileMMA%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/"><![CDATA[<ul> <li><a href="https://github.com/HPC02/cuda_perf/blob/master/src/study_codes/tiled_mma_preview/cute_tiled_mma_preview.cu">cute_tiled_mma_preview.cu</a></li> </ul> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1">// Configure data type.</span>
  <span class="k">using</span> <span class="n">TA</span> <span class="o">=</span> <span class="n">cute</span><span class="o">::</span><span class="n">half_t</span><span class="p">;</span>
  <span class="k">using</span> <span class="n">TB</span> <span class="o">=</span> <span class="n">cute</span><span class="o">::</span><span class="n">half_t</span><span class="p">;</span>
  <span class="k">using</span> <span class="n">TC</span> <span class="o">=</span> <span class="n">cute</span><span class="o">::</span><span class="n">half_t</span><span class="p">;</span>

  <span class="c1">// Configure static "shared memory".</span>
  <span class="c1">// The "shared memory" is actually on host for preview purpose.</span>
  <span class="c1">// For tiled mma, the shared memory layout has to be static.</span>
  <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">bM</span><span class="p">{</span><span class="mi">128</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">/</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">TA</span><span class="p">)};</span>
  <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">bN</span><span class="p">{</span><span class="mi">128</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">/</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">TB</span><span class="p">)};</span>
  <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">bK</span><span class="p">{</span><span class="mi">32</span><span class="p">};</span>
  <span class="k">auto</span> <span class="k">const</span> <span class="n">blk_M</span> <span class="o">=</span> <span class="n">cute</span><span class="o">::</span><span class="n">Int</span><span class="o">&lt;</span><span class="n">bM</span><span class="o">&gt;</span><span class="p">{};</span>
  <span class="k">auto</span> <span class="k">const</span> <span class="n">blk_N</span> <span class="o">=</span> <span class="n">cute</span><span class="o">::</span><span class="n">Int</span><span class="o">&lt;</span><span class="n">bN</span><span class="o">&gt;</span><span class="p">{};</span>
  <span class="k">auto</span> <span class="k">const</span> <span class="n">blk_K</span> <span class="o">=</span> <span class="n">cute</span><span class="o">::</span><span class="n">Int</span><span class="o">&lt;</span><span class="n">bK</span><span class="o">&gt;</span><span class="p">{};</span>

  <span class="k">auto</span> <span class="k">const</span> <span class="n">smem_shape_A</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">make_shape</span><span class="p">(</span><span class="n">blk_M</span><span class="p">,</span> <span class="n">blk_K</span><span class="p">)};</span>
  <span class="k">auto</span> <span class="k">const</span> <span class="n">smem_shape_B</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">make_shape</span><span class="p">(</span><span class="n">blk_N</span><span class="p">,</span> <span class="n">blk_K</span><span class="p">)};</span>
  <span class="k">auto</span> <span class="k">const</span> <span class="n">smem_shape_C</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">make_shape</span><span class="p">(</span><span class="n">blk_M</span><span class="p">,</span> <span class="n">blk_N</span><span class="p">)};</span>
  <span class="k">auto</span> <span class="k">const</span> <span class="n">smem_stride_A</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">make_stride</span><span class="p">(</span><span class="n">cute</span><span class="o">::</span><span class="n">Int</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">blk_M</span><span class="p">)};</span>        <span class="c1">// Column-major</span>
  <span class="k">auto</span> <span class="k">const</span> <span class="n">smem_stride_B</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">make_stride</span><span class="p">(</span><span class="n">cute</span><span class="o">::</span><span class="n">Int</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">blk_N</span><span class="p">)};</span>        <span class="c1">// Column-major</span>
  <span class="k">auto</span> <span class="k">const</span> <span class="n">smem_stride_C</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">make_stride</span><span class="p">(</span><span class="n">cute</span><span class="o">::</span><span class="n">Int</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">blk_M</span><span class="p">)};</span>        <span class="c1">// Column-major</span>
  <span class="k">auto</span> <span class="k">const</span> <span class="n">smem_layout_A</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">make_layout</span><span class="p">(</span><span class="n">smem_shape_A</span><span class="p">,</span> <span class="n">smem_stride_A</span><span class="p">)};</span>  <span class="c1">// (blk_M, blk_K)</span>
  <span class="k">auto</span> <span class="k">const</span> <span class="n">smem_layout_B</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">make_layout</span><span class="p">(</span><span class="n">smem_shape_B</span><span class="p">,</span> <span class="n">smem_stride_B</span><span class="p">)};</span>  <span class="c1">// (blk_N, blk_K)</span>
  <span class="k">auto</span> <span class="k">const</span> <span class="n">smem_layout_C</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">make_layout</span><span class="p">(</span><span class="n">smem_shape_C</span><span class="p">,</span> <span class="n">smem_stride_C</span><span class="p">)};</span>  <span class="c1">// (blk_M, blk_N)</span>

  <span class="k">auto</span> <span class="k">const</span> <span class="n">size_a</span><span class="p">{</span><span class="n">blk_M</span> <span class="o">*</span> <span class="n">blk_K</span><span class="p">};</span>
  <span class="k">auto</span> <span class="k">const</span> <span class="n">size_b</span><span class="p">{</span><span class="n">blk_N</span> <span class="o">*</span> <span class="n">blk_K</span><span class="p">};</span>
  <span class="k">auto</span> <span class="k">const</span> <span class="n">size_c</span><span class="p">{</span><span class="n">blk_M</span> <span class="o">*</span> <span class="n">blk_N</span><span class="p">};</span>

  <span class="k">auto</span> <span class="n">h_A</span> <span class="o">=</span> <span class="n">thrust</span><span class="o">::</span><span class="n">host_vector</span><span class="o">&lt;</span><span class="n">TA</span><span class="o">&gt;</span><span class="p">(</span><span class="n">size_a</span><span class="p">);</span>
  <span class="k">auto</span> <span class="n">h_B</span> <span class="o">=</span> <span class="n">thrust</span><span class="o">::</span><span class="n">host_vector</span><span class="o">&lt;</span><span class="n">TB</span><span class="o">&gt;</span><span class="p">(</span><span class="n">size_b</span><span class="p">);</span>
  <span class="k">auto</span> <span class="n">h_C</span> <span class="o">=</span> <span class="n">thrust</span><span class="o">::</span><span class="n">host_vector</span><span class="o">&lt;</span><span class="n">TC</span><span class="o">&gt;</span><span class="p">(</span><span class="n">size_c</span><span class="p">);</span>

  <span class="c1">// Make tensor for smem_A and smem_B.</span>
  <span class="k">auto</span> <span class="n">smem_tensor_A</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">h_A</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">smem_layout_A</span><span class="p">)};</span>
  <span class="k">auto</span> <span class="n">smem_tensor_B</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">h_B</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">smem_layout_B</span><span class="p">)};</span>
  <span class="k">auto</span> <span class="n">smem_tensor_C</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">h_C</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">smem_layout_C</span><span class="p">)};</span>
</code></pre></div></div> <h2 id="1-tiledmma-配置">1. TiledMMA 配置</h2> <p>位于 SMEM 中的 tile 大小为 $M \times N \times K = 128 \times 128 \times 32$，其中：</p> <ul> <li>A 矩阵为 $M \times K = 128 \times 32$，row-major layout；</li> <li>B 矩阵为 $K \times N = 32 \times 128$，column-major layout；</li> <li>C 矩阵为 $M \times N = 128 \times 128$。</li> </ul> <h3 id="11-mma_atom-配置">1.1. MMA_Atom 配置</h3> <p>MMA_Atom 使用的配置为 <strong>cute::SM80_16x8x16_F16F16F16F16_TN</strong>，使用一个 warp，即 32 个线程处理这个 MMA Atom。处理的 MNK 规模为：$M’ \times N’ \times K’ = 16 \times 8 \times 16$，其中：</p> <ul> <li>A sub-tile 为 $M’ \times K’ = 16 \times 16$；</li> <li>B sub-tile 为 $K’ \times N’ = 16 \times 8$；</li> <li>C sub-tile 为 $M’ \times N’ = 16 \times 8$。</li> </ul> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mma_atom
MMA_Atom
  ThrID:      _32:_1
  Shape_MNK:  (_16,_8,_16)
  LayoutA_TV: ((_4,_8),(_2,_2,_2)):((_32,_1),(_16,_8,_128))
  LayoutB_TV: ((_4,_8),(_2,_2)):((_16,_1),(_8,_64))
  LayoutC_TV: ((_4,_8),(_2,_2)):((_32,_1),(_16,_8))
</code></pre></div></div> <p>分配到线程，每个线程处理的元素数量为：A 矩阵为 2 x 2 x 2 = 8 个元素，B 矩阵为 2 x 2 = 4 个元素，得到 C 矩阵中 2 x 2 = 4 个元素。</p> <p><img src="/assets/images/cuda/20250226/tiled_mma_example/mma_atom_SM80_16x8x16_F16F16F16F16_TN.svg" alt="inverse_tv_layout_SM80_16x8x16_F16F16F16F16_TN"/></p> <h3 id="12-tiled-mma-配置">1.2. Tiled MMA 配置</h3> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1">// Configure tiled MMA.</span>
  <span class="k">using</span> <span class="n">MmaTraits</span>           <span class="o">=</span> <span class="n">cute</span><span class="o">::</span><span class="n">MMA_Traits</span><span class="o">&lt;</span><span class="n">cute</span><span class="o">::</span><span class="n">SM80_16x8x16_F16F16F16F16_TN</span><span class="o">&gt;</span><span class="p">;</span>
  <span class="k">using</span> <span class="n">MmaAtomShape</span>        <span class="o">=</span> <span class="n">MmaTraits</span><span class="o">::</span><span class="n">Shape_MNK</span><span class="p">;</span>
  <span class="k">auto</span> <span class="k">const</span> <span class="n">mma_atom</span>       <span class="o">=</span> <span class="n">cute</span><span class="o">::</span><span class="n">MMA_Atom</span><span class="o">&lt;</span><span class="n">MmaTraits</span><span class="o">&gt;</span><span class="p">{};</span>
  <span class="k">auto</span> <span class="k">const</span> <span class="n">mma_atom_shape</span> <span class="o">=</span> <span class="n">MmaAtomShape</span><span class="p">{};</span>
  <span class="c1">// Repeating the mma atom along the M, N, and K dimensions.</span>
  <span class="c1">// This increases the number of threads to process the tiled MMA.</span>
  <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">MMA_LAYOUT_M</span><span class="p">{</span><span class="mi">2</span><span class="p">};</span>
  <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">MMA_LAYOUT_N</span><span class="p">{</span><span class="mi">2</span><span class="p">};</span>
  <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">MMA_LAYOUT_K</span><span class="p">{</span><span class="mi">1</span><span class="p">};</span>
  <span class="k">auto</span> <span class="n">mma_layout</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">make_layout</span><span class="p">(</span>
    <span class="n">cute</span><span class="o">::</span><span class="n">make_shape</span><span class="p">(</span><span class="n">cute</span><span class="o">::</span><span class="n">Int</span><span class="o">&lt;</span><span class="n">MMA_LAYOUT_M</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">cute</span><span class="o">::</span><span class="n">Int</span><span class="o">&lt;</span><span class="n">MMA_LAYOUT_N</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">cute</span><span class="o">::</span><span class="n">Int</span><span class="o">&lt;</span><span class="n">MMA_LAYOUT_K</span><span class="o">&gt;</span><span class="p">{}))};</span>
  <span class="c1">// Repeating the mma processing along the M, N, and K dimensions.</span>
  <span class="c1">// This does not increase the number of threads to process the tiled MMA.</span>
  <span class="c1">// But the number of registers required for processing the tiled MMA increases.</span>
  <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">NUM_MMA_TILE_M</span><span class="p">{</span><span class="mi">1</span><span class="p">};</span>
  <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">NUM_MMA_TILE_N</span><span class="p">{</span><span class="mi">2</span><span class="p">};</span>
  <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">NUM_MMA_TILE_K</span><span class="p">{</span><span class="mi">1</span><span class="p">};</span>
  <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">MMA_TILE_M</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">get</span><span class="o">&lt;</span><span class="mi">0</span><span class="o">&gt;</span><span class="p">(</span><span class="n">mma_atom_shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">MMA_LAYOUT_M</span> <span class="o">*</span> <span class="n">NUM_MMA_TILE_M</span><span class="p">};</span>
  <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">MMA_TILE_N</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">get</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">(</span><span class="n">mma_atom_shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">MMA_LAYOUT_N</span> <span class="o">*</span> <span class="n">NUM_MMA_TILE_N</span><span class="p">};</span>
  <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">MMA_TILE_K</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">get</span><span class="o">&lt;</span><span class="mi">2</span><span class="o">&gt;</span><span class="p">(</span><span class="n">mma_atom_shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">MMA_LAYOUT_K</span> <span class="o">*</span> <span class="n">NUM_MMA_TILE_K</span><span class="p">};</span>
  <span class="k">auto</span> <span class="n">mma_tile</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">make_tile</span><span class="p">(</span><span class="n">cute</span><span class="o">::</span><span class="n">Int</span><span class="o">&lt;</span><span class="n">MMA_TILE_M</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">cute</span><span class="o">::</span><span class="n">Int</span><span class="o">&lt;</span><span class="n">MMA_TILE_N</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">cute</span><span class="o">::</span><span class="n">Int</span><span class="o">&lt;</span><span class="n">MMA_TILE_K</span><span class="o">&gt;</span><span class="p">{})};</span>
  <span class="k">auto</span> <span class="n">tiled_mma</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">make_tiled_mma</span><span class="p">(</span><span class="n">mma_atom</span><span class="p">,</span> <span class="n">mma_layout</span><span class="p">,</span> <span class="n">mma_tile</span><span class="p">)};</span>
</code></pre></div></div> <p>在 M 维度上，MMA Atom 重复 2 次，在 N 维度上重复 2 次，在 K 维度上重复 1 次。一共需要 2 x 2 x 1 = 4 个 MMA Atom 来处理这个 tiled MMA。每个 Atom 由一个 warp（32 个线程）处理，整个 tiled MMA 由 4 个 warp（128 个线程）处理。即 <strong>ThrLayoutVMNK = (_32,_2,_2,_1):(_1,_32,_64,_0)</strong>。经过此配置后，能处理的 MNK 规模为 $(M’ \times 2) \times (N’ \times 2) \times (K’ \times 1) = 32 \times 16 \times 16$。</p> <p>另外，通过配置 PermutationMNK（对应以前版本的 ValLayoutMNK），使得一个 tiled MMA 在 M/N/K 方向上处理更多的元素（即一个线程处理更多的元素）。这里配置 N 维度上乘以 2，得到该 tiled MMA 处理的 MNK 规模为 $32 \times 32 \times 16$，即 <strong>PermutationMNK: (_32,_32,_16)</strong>。</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tiled_mma
TiledMMA
  ThrLayoutVMNK:  (_32,_2,_2,_1):(_1,_32,_64,_0)
  PermutationMNK: (_32,_32,_16)
MMA_Atom
  ThrID:      _32:_1
  Shape_MNK:  (_16,_8,_16)
  LayoutA_TV: ((_4,_8),(_2,_2,_2)):((_32,_1),(_16,_8,_128))
  LayoutB_TV: ((_4,_8),(_2,_2)):((_16,_1),(_8,_64))
  LayoutC_TV: ((_4,_8),(_2,_2)):((_32,_1),(_16,_8))
</code></pre></div></div> <p><img src="/assets/images/cuda/20250226/tiled_mma_example/tiled_mma_SM80_16x8x16_F16F16F16F16_TN.svg" alt="tile_mma_SM80_16x8x16_F16F16F16F16_TN"/></p> <h3 id="13-tiled-mma-划分总结">1.3. Tiled MMA 划分总结</h3> <p>以$M \times N \times K = 128 \times 128 \times 32$，以及 MMA Atom <strong>SM80_16x8x16_F16F16F16F16_TN</strong> 为例，MNK 三个维度分块划分（计算公式），可以按如下几种：</p> <ul> <li>$\frac{M}{M’} \times \frac{N}{N’} \times \frac{K}{K’}$ = $\frac{128}{16} \times \frac{128}{8} \times \frac{32}{16}$ = $8 \times 16 \times 2$ = $256$，即 MMA Atom 在 M 维度重复 8 次，N 维度 重复16 次，K 维度重复 2 次。Atom 总共需要循环 <strong>256</strong> 次。</li> <li>$\frac{M}{M’ \times MMA_LAYOUT_M} \times \frac{N}{N’ \times MMA_LAYOUT_N} \times \frac{K}{K’ \times MMA_LAYOUT_K}$ = $\frac{128}{16 \times 2} \times \frac{128}{8 \times 2} \times \frac{32}{16 \times 1}$ = $4 \times 8 \times 2$ = $64$，即 tiled MMA 在 M 维度重复 2 次，N 维度重复 2 次，K 维度重复 1 次。Atom 总共需要循环 <strong>64</strong> 次。</li> <li>其他配置方式，类似上面两种计算方式。</li> </ul> <p>一个 thread block 如何划分一个 tiled MMA，从性能上需要综合考虑以下几个因素：</p> <ul> <li>SM 上可用的寄存器数量，来确定一个 thread block 中可以有多少个线程来处理这个 tiled MMA。每个线程处理的元素数量越多，需要的寄存器数量就越多。</li> <li>在寄存器够用的情况下，尽量让一个 thread block 中的线程数量能够充分利用 SM 上的计算资源（即 CUDA Core、Tensor Core）。每个 tiled MMA 需要多少个线程来处理，取决于 MMA Atom 的配置以及 tiled MMA 的配置。</li> </ul> <h2 id="2-内存分块以及-tiledcopy">2. 内存分块以及 TiledCopy</h2> <p>在将 thread block 对应的 tile 内存再次分解为线程 sub-tile 过程中，使用 CuTe 分块，有三种方式：</p> <ul> <li>使用 partition 分块，得到 SMEM / GMEM slice。</li> <li>使用 partition_fragment 分块，得到寄存器片段（register fragment）。</li> <li>使用 TiledCopy / ldmatrix 进行分块以及传输。</li> </ul> <h3 id="21-使用-partitionpartition_fragment-分块">2.1. 使用 partition、partition_fragment 分块</h3> <p><strong>partition_A/B/C</strong></p> <p>使用 partition 方法，获取原始 layout 的分块，即生成一个 slice。分块之后，数据还是在 SMEM / GMEM 中，且保留了原有的 tile 的 stride 信息。</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">auto</span> <span class="n">thread_mma</span><span class="p">{</span><span class="n">tiled_mma</span><span class="p">.</span><span class="n">get_slice</span><span class="p">(</span><span class="n">THREAD_IDX</span><span class="p">)};</span>

  <span class="k">auto</span> <span class="n">thread_layout_C_smem_tensor_A_no_tiled_copy</span><span class="p">{</span><span class="n">thread_mma</span><span class="p">.</span><span class="n">partition_A</span><span class="p">(</span><span class="n">smem_tensor_A</span><span class="p">)};</span>  <span class="c1">// (MMA, MMA_M, MMA_K)</span>
  <span class="k">auto</span> <span class="n">thread_layout_C_smem_tensor_B_no_tiled_copy</span><span class="p">{</span><span class="n">thread_mma</span><span class="p">.</span><span class="n">partition_B</span><span class="p">(</span><span class="n">smem_tensor_B</span><span class="p">)};</span>  <span class="c1">// (MMA, MMA_N, MMA_K)</span>
  <span class="k">auto</span> <span class="n">thread_layout_C_smem_tensor_C_no_tiled_copy</span><span class="p">{</span><span class="n">thread_mma</span><span class="p">.</span><span class="n">partition_C</span><span class="p">(</span><span class="n">smem_tensor_C</span><span class="p">)};</span>  <span class="c1">// (MMA, MMA_M, MMA_N)</span>
</code></pre></div></div> <p>打印信息如下：</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>thread_layout_C_smem_tensor_A_no_tiled_copy
ptr[16b](0x5c6c073e78c0) o ((_2,_2,_2),_4,_2):((_128,_8,_1024),_32,_2048)
thread_layout_C_smem_tensor_B_no_tiled_copy
ptr[16b](0x5c6c073e98d0) o ((_2,_2),_8,_2):((_128,_1024),_16,_2048)
thread_layout_C_smem_tensor_C_no_tiled_copy
ptr[16b](0x5c6c073eb8e0) o ((_2,_2),_4,_8):((_128,_8),_32,_2048)
</code></pre></div></div> <p>其中，含义如下：</p> <table> <thead> <tr> <th>维度</th> <th>含义</th> </tr> </thead> <tbody> <tr> <td>MMA (第0维)</td> <td>一次 tiled MMA 计算中该线程负责的元素</td> </tr> <tr> <td>MMA_M (第1维)</td> <td>沿 M 方向需要循环的次数</td> </tr> <tr> <td>MMA_K (第2维)</td> <td>沿 K 方向需要循环的次数</td> </tr> </tbody> </table> <p>具体到 A/B/C 矩阵上，含义如下：</p> <table> <thead> <tr> <th>矩阵</th> <th>shape</th> <th>解释</th> </tr> </thead> <tbody> <tr> <td>A</td> <td>((_2,_2,_2), _4, _2)</td> <td>MMA=8个元素, M循环4次, K循环2次</td> </tr> <tr> <td>B</td> <td>((_2,_2), _8, _2)</td> <td>MMA=4个元素, N循环8次, K循环2次</td> </tr> <tr> <td>C</td> <td>((_2,_2), _4, _8)</td> <td>MMA=4个元素, M循环4次, N循环8次</td> </tr> </tbody> </table> <p>按线程切分之后，保留的第一个 mode，另外两个 mode 含义是（以 A 为例），MMA Atom 按 M 维度循环 4 次，K 维度循环 2 次。对于 B/C 矩阵类似。</p> <blockquote> <p>从打印信息看出，不论是直接使用 <strong>thread_layout_C_smem_tensor_A/B_no_tiled_copy</strong>，还是将其拷贝到寄存器，由于不连续，导致线程每次访问 2 _ 2 _ 2 = 8 个元素时，需要分开拷贝，即分 8 次访问 SMEM / GMEM 来加载数据到寄存器中。</p> </blockquote> <p><strong>partition_fragment_A/B/C</strong></p> <p>partition_fragment 则创建寄存器片段（register fragment），以复用寄存器数据。分块之后，数据在寄存器中，且不保留原有 tile 的 stride 信息，而是变为紧凑型布局。线程在做 gemm 之前，使用 copy 将数据从 SMEM 中加载到寄存器中。</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">auto</span> <span class="n">thread_layout_C_register_tensor_A</span><span class="p">{</span><span class="n">thread_mma</span><span class="p">.</span><span class="n">partition_fragment_A</span><span class="p">(</span><span class="n">smem_tensor_A</span><span class="p">)};</span>  <span class="c1">// (MMA, MMA_M, MMA_K)</span>
  <span class="k">auto</span> <span class="n">thread_layout_C_register_tensor_B</span><span class="p">{</span><span class="n">thread_mma</span><span class="p">.</span><span class="n">partition_fragment_B</span><span class="p">(</span><span class="n">smem_tensor_B</span><span class="p">)};</span>  <span class="c1">// (MMA, MMA_N, MMA_K)</span>
  <span class="k">auto</span> <span class="n">thread_layout_C_register_tensor_C</span><span class="p">{</span><span class="n">thread_mma</span><span class="p">.</span><span class="n">partition_fragment_C</span><span class="p">(</span><span class="n">smem_tensor_C</span><span class="p">)};</span>  <span class="c1">// (MMA, MMA_M, MMA_N)</span>
</code></pre></div></div> <p>打印信息如下：</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>thread_layout_C_register_tensor_A
ptr[16b](0x7ffc34e465f0) o ((_2,_2,_2),_4,_2):((_1,_2,_4),_8,_32)
thread_layout_C_register_tensor_B
ptr[16b](0x7ffc34e46670) o ((_2,_2),_8,_2):((_1,_2),_4,_32)
thread_layout_C_register_tensor_C
ptr[16b](0x7ffc34e466f0) o ((_2,_2),_4,_8):((_1,_2),_4,_16)
</code></pre></div></div> <p><strong>总结</strong></p> <p>使用 partition / partition_fragment 分块，分块数据可能不连续，导致需要多次访问 SMEM / GMEM。使用合适的 ldmatrix 可以一次将一次计算所需要的 sub-tile 数据拷贝到寄存器。</p> <h2 id="22-使用-tiledcopy--ldmatrix-进行分块以及传输">2.2. 使用 TiledCopy / ldmatrix 进行分块以及传输</h2> <p>前面使用的 partition / partition_fragment 方式，直接使用 TiledMMA/ThrMMA 分块得到的。使用 TiledCopy / ldmatrix 进行分块以及传输。设置 TiledCopy 需要的 Copy_Atom、CopyTraits（layout 信息），并使其传输的 sub-tile 大小与 tiled MMA 的计算需求一致。</p> <h3 id="221-copy-atom-配置">2.2.1. Copy Atom 配置</h3> <p>针对 A、B，使用 <strong>cute::SM75_U16x8_LDSM_T</strong> 生成 Copy Atom 来复制 A、B 的 sub-tile，其对应的 PTX 为：</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ldmatrix</span><span class="p">.</span><span class="n">sync</span><span class="p">.</span><span class="n">aligned</span><span class="p">.</span><span class="n">m8n8</span><span class="p">.</span><span class="n">x4</span><span class="p">.</span><span class="n">trans</span><span class="p">.</span><span class="n">shared</span><span class="p">.</span><span class="n">b16</span> <span class="p">{</span><span class="n">r0</span><span class="p">,</span> <span class="n">r1</span><span class="p">,</span> <span class="n">r2</span><span class="p">,</span> <span class="n">r3</span><span class="p">},</span> <span class="p">[</span><span class="n">addr</span><span class="p">];</span>
</code></pre></div></div> <p>即使用一个 warp（32 个线程）同时加载一个 sub-tile 的数据到寄存器中。</p> <blockquote> <p>ldmatrix 只支持16位数据，不支持32位数据；另外 ldmatrix 是 PTX 指令，对应到 ncu 中看到的 LDSM 指令。x1 表示使用前 8 个线程，x2、x4 依次类推。m8n8 表示 load 操作的子块大小为 8x8，x4 则表示同时加载 4 个子块。</p> </blockquote> <p><strong>cute::SM75_U16x8_LDSM_T</strong> 打印信息如下：</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>copy_atom_A
Copy_Atom
  ThrID:        _32:_1
  ValLayoutSrc: (_32,_8):(_8,_1)
  ValLayoutDst: ((_4,_8),(_1,_2,_4)):((_16,_1),(_1,_8,_64))
  ValLayoutRef: ((_4,_8),(_1,_2,_4)):((_16,_1),(_1,_8,_64))
  ValueType:    16b

copy_atom_B
Copy_Atom
  ThrID:        _32:_1
  ValLayoutSrc: (_32,_8):(_8,_1)
  ValLayoutDst: ((_4,_8),(_1,_2,_4)):((_16,_1),(_1,_8,_64))
  ValLayoutRef: ((_4,_8),(_1,_2,_4)):((_16,_1),(_1,_8,_64))
  ValueType:    16b
</code></pre></div></div> <p>在前面 TiledMMA 的配置中，经过 AtomLayout 以及 Permutation，最终得到的 tiled MMA 处理的 sub-tile 大小为 $M’ \times N’ \times K’ = 32 \times 32 \times 16$。其中 A 矩阵的 sub-tile 大小为 $M’ \times K’ = 32 \times 16$，B 矩阵的 sub-tile 大小为 $K’ \times N’ = 16 \times 32$。</p> <p>使用<strong>SM75_U16x8_LDSM_T</strong>，其一次拷贝的 sub-tile 大小为 $32 \times 8 = 256$，即对应上面打印信息中的 <strong>ValLayoutSrc: (_32,_8):(_8,_1)</strong>。因此，TiledCopy 的 Copy Atom 配置满足一次加载 执行一个 Tiled MMA 所需要的数据。</p> <p>另外，在 Tiled MMA 配置中，B 配置了 permutation，使得 B 矩阵的 sub-tile 大小与 A 矩阵大小一致，否则针对 B，就需要选择其他的 Copy Atom 来满足 tiled MMA 的计算需求。</p> <h3 id="222-tiledcopy-以及-threadcopy-创建">2.2.2. TiledCopy 以及 ThreadCopy 创建</h3> <p>创建 TiledCopy，Copy_Atom 配置如上<strong>SM75_U16x8_LDSM_T</strong>，TV-Layout 则由上述的 Tiled MMA 给出。代码如下：</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">auto</span> <span class="n">copy_atom_A</span> <span class="o">=</span> <span class="n">cute</span><span class="o">::</span><span class="n">Copy_Atom</span><span class="o">&lt;</span><span class="n">cute</span><span class="o">::</span><span class="n">SM75_U16x8_LDSM_T</span><span class="p">,</span> <span class="n">TA</span><span class="o">&gt;</span><span class="p">{};</span>
  <span class="k">auto</span> <span class="n">copy_atom_B</span> <span class="o">=</span> <span class="n">cute</span><span class="o">::</span><span class="n">Copy_Atom</span><span class="o">&lt;</span><span class="n">cute</span><span class="o">::</span><span class="n">SM75_U16x8_LDSM_T</span><span class="p">,</span> <span class="n">TB</span><span class="o">&gt;</span><span class="p">{};</span>

  <span class="k">auto</span> <span class="n">smem_tiled_copy_A</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">make_tiled_copy_A</span><span class="p">(</span><span class="n">copy_atom_A</span><span class="p">,</span> <span class="n">tiled_mma</span><span class="p">)};</span>
  <span class="k">auto</span> <span class="n">smem_tiled_copy_B</span><span class="p">{</span><span class="n">cute</span><span class="o">::</span><span class="n">make_tiled_copy_B</span><span class="p">(</span><span class="n">copy_atom_B</span><span class="p">,</span> <span class="n">tiled_mma</span><span class="p">)};</span>
</code></pre></div></div> <p>Tiled Copy 信息如下：</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>smem_tiled_copy_A
TiledCopy
  Tiler_MN:       (_32,_16)
  TiledLayout_TV: ((_4,_8,_2,_2),((_2,_2,_2),(_1,_1))):((_64,_1,_16,_0),((_32,_8,_256),(_0,_0)))
Copy_Atom
  ThrID:        _32:_1
  ValLayoutSrc: (_32,_8):(_8,_1)
  ValLayoutDst: ((_4,_8),(_1,_2,_4)):((_16,_1),(_1,_8,_64))
  ValLayoutRef: ((_4,_8),(_1,_2,_4)):((_16,_1),(_1,_8,_64))
  ValueType:    16b

smem_tiled_copy_B
TiledCopy
  Tiler_MN:       (_32,_16)
  TiledLayout_TV: ((_4,_8,_2,_2),((_2,_2),(_2,_1))):((_64,_1,_0,_8),((_32,_256),(_16,_0)))
Copy_Atom
  ThrID:        _32:_1
  ValLayoutSrc: (_32,_8):(_8,_1)
  ValLayoutDst: ((_4,_8),(_1,_2,_4)):((_16,_1),(_1,_8,_64))
  ValLayoutRef: ((_4,_8),(_1,_2,_4)):((_16,_1),(_1,_8,_64))
  ValueType:    16b
</code></pre></div></div> <p><strong>使用 Thread Copy 以及创建本线程 sub-tile</strong></p> <p>分为两步，首先使用 <strong>ThrCopy&lt;…&gt;::partition_S</strong> 获取线程的 tensor，再使用 <strong>ThrCopy&lt;…&gt;::retile_D</strong> 获取调整 shape 之后的 tensor。代码如下：</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">auto</span> <span class="n">smem_thread_copy_A</span><span class="p">{</span><span class="n">smem_tiled_copy_A</span><span class="p">.</span><span class="n">get_slice</span><span class="p">(</span><span class="n">THREAD_IDX</span><span class="p">)};</span>
  <span class="k">auto</span> <span class="n">smem_thread_copy_B</span><span class="p">{</span><span class="n">smem_tiled_copy_B</span><span class="p">.</span><span class="n">get_slice</span><span class="p">(</span><span class="n">THREAD_IDX</span><span class="p">)};</span>

  <span class="k">auto</span> <span class="n">thread_layout_C_smem_tensor_A_tiled_copy</span><span class="p">{</span><span class="n">smem_thread_copy_A</span><span class="p">.</span><span class="n">partition_S</span><span class="p">(</span><span class="n">smem_tensor_A</span><span class="p">)};</span>
  <span class="k">auto</span> <span class="n">thread_layout_C_smem_tensor_B_tiled_copy</span><span class="p">{</span><span class="n">smem_thread_copy_B</span><span class="p">.</span><span class="n">partition_S</span><span class="p">(</span><span class="n">smem_tensor_B</span><span class="p">)};</span>

  <span class="k">auto</span> <span class="n">thread_layout_C_register_tensor_A_copy_view</span><span class="p">{</span><span class="n">smem_thread_copy_A</span><span class="p">.</span><span class="n">retile_D</span><span class="p">(</span><span class="n">thread_layout_C_register_tensor_A</span><span class="p">)};</span>
  <span class="k">auto</span> <span class="n">thread_layout_C_register_tensor_B_copy_view</span><span class="p">{</span><span class="n">smem_thread_copy_B</span><span class="p">.</span><span class="n">retile_D</span><span class="p">(</span><span class="n">thread_layout_C_register_tensor_B</span><span class="p">)};</span>
</code></pre></div></div> <p><strong>thread_layout_C_smem_tensor_A/B_tiled_copy</strong> 作为源 tensor，他们的信息如下：</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>thread_layout_C_smem_tensor_A_tiled_copy
ptr[16b](0x57b7b93248c0) o ((_8,_1),_4,_2):((_1,_0),_32,_2048)
thread_layout_C_smem_tensor_B_tiled_copy
ptr[16b](0x57b7b93268d0) o ((_8,_1),_4,_2):((_1,_0),_32,_2048)
</code></pre></div></div> <p>作为目的 tensor 的 <strong>thread_layout_C_register_tensor_A/B</strong>（由 <strong>ThrMMA&lt;…&gt;::partition_fragment_A/B</strong> 获取），其信息如下：</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>thread_layout_C_register_tensor_A
ptr[16b](0x7ffc34e465f0) o ((_2,_2,_2),_4,_2):((_1,_2,_4),_8,_32)
thread_layout_C_register_tensor_B
ptr[16b](0x7ffc34e46670) o ((_2,_2),_8,_2):((_1,_2),_4,_32)
</code></pre></div></div> <p>所以需要对目的 tensor 进行调整，使得其 shape 与源 tensor 一致。调整之后的目的 tensor <strong>thread_layout_C_register_tensor_A/B_copy_view</strong> 的信息如下：</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>thread_layout_C_register_tensor_A_copy_view
ptr[16b](0x7ffd7a129350) o ((_8,_1),_4,_2):((_1,_0),_8,_32)
thread_layout_C_register_tensor_B_copy_view
ptr[16b](0x7ffd7a1293d0) o ((_8,_1),_4,_2):((_1,_0),_8,_32)
</code></pre></div></div> <h2 id="参考及资料">参考及资料</h2> <ul> <li><a href="https://leimao.github.io/blog/CuTe-Tiled-MMA/">CuTe Tiled MMA</a>：Mao Lei 博客</li> <li><a href="https://github.com/leimao/CUTLASS-Examples/tree/main/examples/cute_general_matrix_multiplication">CuTe General Matrix Multiplication</a>：Mao Lei GitHub GEMM 代码</li> <li><a href="https://github.com/NVIDIA/cutlass/blob/main/media/docs/cpp/cute/0t_mma_atom.md">0t_mma_atom</a>：CUTLASS-CuTe 0t_mma_atom 文档 <strong>待阅读</strong></li> <li><a href="https://leimao.github.io/blog/CuTe-ldmatrix/">CuTe ldmatrix</a>：Mao Lei 博客 ldmatrix <strong>待阅读</strong></li> <li><a href="https://zhuanlan.zhihu.com/p/697228676">ldmatrix指令例子和其带来的smem bank冲突</a></li> <li><a href="https://zhuanlan.zhihu.com/p/696231622">ldmatrix与swizzle（笔记）</a></li> </ul>]]></content><author><name></name></author><category term="CUDA"/><category term="CUDA"/><summary type="html"><![CDATA[cute_tiled_mma_preview.cu]]></summary></entry></feed>