<!DOCTYPE html> <html lang="zh-CN"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> GEMM 版本1：使用 CuTe 实现一个 naive GEMM | Roderick Huang </title> <meta name="author" content="Roderick Huang"> <meta name="description" content="Roderick Huang 的个人博客，记录工作与技术。 "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="manifest" href="/manifest.json"> <meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff"> <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1a1a2e"> <script>
  if ('serviceWorker' in navigator) {
    window.addEventListener('load', function () {
      navigator.serviceWorker.register('/sw.js');
    });
  }
</script> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?v=6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://hxf0223.github.io/blog/2025/GEMM1-Cute-naive-GEMM/"> <script src="/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Roderick</span> Huang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">GEMM 版本1：使用 CuTe 实现一个 naive GEMM</h1> <p class="post-meta"> Created on February 26, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/cuda"> <i class="fa-solid fa-hashtag fa-sm"></i> CUDA</a>   ·   <a href="/blog/category/cuda"> <i class="fa-solid fa-tag fa-sm"></i> CUDA</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><img src="/assets/images/cuda/20250226/gemm_tile_naive_cute/gemm_naive_tile.jpg" alt="tile_gemm"></p> <h2 id="1-navie-tile-gemm">1. navie tile GEMM</h2> <ul> <li>代码文件：<a href="https://github.com/HPC02/cuda_perf/blob/master/src/cute_gemm/gemm_tile_naive.cu" rel="external nofollow noopener" target="_blank">navie tile GEMM</a> </li> </ul> <p>基于分块矩阵乘法的简单实现，按照 Thread Block 将矩阵划分为多个tile进行计算，在 Thread Block内，再次将 tile 划分为多个子块，由每个线程负责计算子块。</p> <p>使用 Shared Memory 来缓存 tile 数据，减少全局内存访问次数。每个线程负责从全局内存中复制 tile 内的一小块内存到 Shared Memory。</p> <ul> <li>循环展开<code class="language-plaintext highlighter-rouge">#pragma unroll</code>优化加载和计算部分的循环，提高指令级并行性（消耗更多寄存器资源），本代码测试整体运行时间提升<code class="language-plaintext highlighter-rouge">15%</code>左右。</li> </ul> <h2 id="2-cute-版本-naive-tile-gemm">2. CuTe 版本 naive tile GEMM</h2> <ul> <li>代码文件：<a href="https://github.com/HPC02/cuda_perf/blob/master/src/cute_gemm/gemm_tile_naive_cute.cu" rel="external nofollow noopener" target="_blank">CuTe naive tile GEMM</a> </li> </ul> <p>使用 CuTe 库重写的分块矩阵乘法，使用 slice-k 方法，即分块（tile）沿着 K 维度累加所有结果子矩阵。</p> <blockquote> <p>使用 NVIDIA CuTe 库重写的分块矩阵乘法实现，采用 <code class="language-plaintext highlighter-rouge">cute::gemm</code> 期望的标准布局。</p> </blockquote> <h3 id="21-矩阵布局约定">2.1. 矩阵布局约定</h3> <p>采用 <strong>BLAS/Fortran 风格的列主序 (Column-major)</strong>：</p> <table> <thead> <tr> <th>Tensor</th> <th>Shape</th> <th>Stride</th> <th>说明</th> </tr> </thead> <tbody> <tr> <td>A</td> <td>(M, K)</td> <td>(1, M)</td> <td>列主序，M方向连续</td> </tr> <tr> <td>B</td> <td>(N, K)</td> <td>(1, N)</td> <td>列主序，存储 B^T</td> </tr> <tr> <td>C</td> <td>(M, N)</td> <td>(1, M)</td> <td>列主序，M方向连续</td> </tr> </tbody> </table> <blockquote> <p>矩阵参数，以及划分参数：M=1024，N=1024，K=1024*8，BM=64，BN=64，BK=16，TM=8，TN=8。 <strong>关键点</strong>：B 矩阵以 (N, K) 形式存储，实际上是原始 B(K, N) 的转置。这是 <code class="language-plaintext highlighter-rouge">cute::gemm</code> 的标准输入格式。</p> </blockquote> <p>创建的矩阵 A、B、C 的 tensor 视图如下：</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// A: (M, K) 列主序, stride = (1, M)</span>
<span class="c1">// B: (N, K) 列主序, stride = (1, N)  -- 注意这里存的是B的转置</span>
<span class="c1">// C: (M, N) 列主序, stride = (1, M)</span>
<span class="n">Tensor</span> <span class="n">mA</span> <span class="o">=</span> <span class="n">make_tensor</span><span class="p">(</span><span class="n">make_gmem_ptr</span><span class="p">(</span><span class="n">Aptr</span><span class="p">),</span> <span class="n">make_shape</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">K</span><span class="p">),</span> <span class="n">make_stride</span><span class="p">(</span><span class="n">Int</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">M</span><span class="p">));</span>
<span class="n">Tensor</span> <span class="n">mB</span> <span class="o">=</span> <span class="n">make_tensor</span><span class="p">(</span><span class="n">make_gmem_ptr</span><span class="p">(</span><span class="n">Bptr</span><span class="p">),</span> <span class="n">make_shape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">K</span><span class="p">),</span> <span class="n">make_stride</span><span class="p">(</span><span class="n">Int</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">N</span><span class="p">));</span>
<span class="n">Tensor</span> <span class="n">mC</span> <span class="o">=</span> <span class="n">make_tensor</span><span class="p">(</span><span class="n">make_gmem_ptr</span><span class="p">(</span><span class="n">Cptr</span><span class="p">),</span> <span class="n">make_shape</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">make_stride</span><span class="p">(</span><span class="n">Int</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">M</span><span class="p">));</span>
</code></pre></div></div> <blockquote> <p>kernel 的 dimensions 配置为：</p> </blockquote> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dim3</span> <span class="nf">gridDim</span><span class="p">(</span><span class="n">N</span> <span class="o">/</span> <span class="n">BN</span><span class="p">,</span> <span class="n">M</span> <span class="o">/</span> <span class="n">BM</span><span class="p">);</span>   <span class="c1">// (16, 16)</span>
<span class="n">dim3</span> <span class="nf">blockDim</span><span class="p">(</span><span class="n">BN</span> <span class="o">/</span> <span class="n">TN</span><span class="p">,</span> <span class="n">BM</span> <span class="o">/</span> <span class="n">TM</span><span class="p">);</span><span class="c1">// (8, 8)</span>
</code></pre></div></div> <h3 id="22-cute-实现分块分割线程分区拷贝及计算">2.2. CuTe 实现：分块分割、线程分区、拷贝及计算</h3> <p>以矩阵 A 为例，矩阵 A 在 M 纬度上，每个 Thread Block 负责处理 BM 行（复制 + GEMM）；在 K 维度上，Thread Block 负责处理 BK 列。Thread Block 以二维的方式划分，需要的 Thread Block 数量为 (M/BM, N/BN)，即划分的 tile 数量；每个 Thread Block 内的线程数量为 (BM/TM, BN/TN)，即同样以二维的方式将 tile 再次划分给 Thread Block 内的线程。</p> <p>使用 slice-k 方法，Thread Block 需要循环遍历 K 维度，将矩阵 A 分块加载到 SMEM 中。所以创建的 tile tensor 视图是一个三维 tensor： (BM, BK, K/BK) 大小。矩阵 B 同理，得到的三维 tensor：(BN, BK, K/BK)。</p> <p>由于分块计算得到的 C 矩阵 tile 大小为 (BM, BN)，所以需要取得矩阵 C 的 tile tensor。</p> <blockquote> <p>矩阵 A、B 分块 GEMM 需要的 SMEM。其本质是缓存，大小为一个 tile 大小。即针对矩阵 A，Thread Block 每次从 GMEM 中依次取得 (BM, BK) 分块大小复制到 SMEM，然后沿着 K 维度循环 for(product)。定义如下：</p> </blockquote> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">__shared__</span> <span class="n">T</span> <span class="n">smemA</span><span class="p">[</span><span class="n">BM</span> <span class="o">*</span> <span class="n">BK</span><span class="p">];</span>
<span class="n">__shared__</span> <span class="n">T</span> <span class="n">smemB</span><span class="p">[</span><span class="n">BN</span> <span class="o">*</span> <span class="n">BK</span><span class="p">];</span>

<span class="c1">// sA: (BM, BK) 列主序, stride = (1, BM)</span>
<span class="c1">// sB: (BN, BK) 列主序, stride = (1, BN)</span>
<span class="n">Tensor</span> <span class="n">sA</span> <span class="o">=</span> <span class="n">make_tensor</span><span class="p">(</span><span class="n">make_smem_ptr</span><span class="p">(</span><span class="n">smemA</span><span class="p">),</span> <span class="n">make_shape</span><span class="p">(</span><span class="n">Int</span><span class="o">&lt;</span><span class="n">BM</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">Int</span><span class="o">&lt;</span><span class="n">BK</span><span class="o">&gt;</span><span class="p">{}),</span> <span class="n">make_stride</span><span class="p">(</span><span class="n">Int</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">Int</span><span class="o">&lt;</span><span class="n">BM</span><span class="o">&gt;</span><span class="p">{}));</span>
<span class="n">Tensor</span> <span class="n">sB</span> <span class="o">=</span> <span class="n">make_tensor</span><span class="p">(</span><span class="n">make_smem_ptr</span><span class="p">(</span><span class="n">smemB</span><span class="p">),</span> <span class="n">make_shape</span><span class="p">(</span><span class="n">Int</span><span class="o">&lt;</span><span class="n">BN</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">Int</span><span class="o">&lt;</span><span class="n">BK</span><span class="o">&gt;</span><span class="p">{}),</span> <span class="n">make_stride</span><span class="p">(</span><span class="n">Int</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">Int</span><span class="o">&lt;</span><span class="n">BN</span><span class="o">&gt;</span><span class="p">{}));</span>
</code></pre></div></div> <h3 id="221-分块操作">2.2.1. 分块操作</h3> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// 创建全局内存 tensor 视图</span>
<span class="n">Tensor</span> <span class="n">gA</span> <span class="o">=</span> <span class="n">local_tile</span><span class="p">(</span><span class="n">mA</span><span class="p">,</span> <span class="n">make_tile</span><span class="p">(</span><span class="n">Int</span><span class="o">&lt;</span><span class="n">BM</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">Int</span><span class="o">&lt;</span><span class="n">BK</span><span class="o">&gt;</span><span class="p">{}),</span> <span class="n">make_coord</span><span class="p">(</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="p">,</span> <span class="n">_</span><span class="p">));</span>           <span class="c1">// (BM, BK, k)</span>
<span class="n">Tensor</span> <span class="n">gB</span> <span class="o">=</span> <span class="n">local_tile</span><span class="p">(</span><span class="n">mB</span><span class="p">,</span> <span class="n">make_tile</span><span class="p">(</span><span class="n">Int</span><span class="o">&lt;</span><span class="n">BN</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">Int</span><span class="o">&lt;</span><span class="n">BK</span><span class="o">&gt;</span><span class="p">{}),</span> <span class="n">make_coord</span><span class="p">(</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">));</span>           <span class="c1">// (BN, BK, k)</span>
<span class="n">Tensor</span> <span class="n">gC</span> <span class="o">=</span> <span class="n">local_tile</span><span class="p">(</span><span class="n">mC</span><span class="p">,</span> <span class="n">make_tile</span><span class="p">(</span><span class="n">Int</span><span class="o">&lt;</span><span class="n">BM</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">Int</span><span class="o">&lt;</span><span class="n">BN</span><span class="o">&gt;</span><span class="p">{}),</span> <span class="n">make_coord</span><span class="p">(</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="p">,</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">));</span>  <span class="c1">// (BM, BN)</span>
</code></pre></div></div> <p>按照语义理解，A 矩阵使用 shape(BM, BK) 沿着 M 维度以及 K 维度进行切分，即将其划分为若干 tile，每个 tile 的大小为 (BM, BK)。而后，使用 <code class="language-plaintext highlighter-rouge">make_coord(blockIdx.y, _)</code> 取得第 <code class="language-plaintext highlighter-rouge">blockIdx.y</code> 个 tile，在 K 维度上使用 <code class="language-plaintext highlighter-rouge">_</code> 表示取所有 tile，所以生成了一个三维的 Tensor。由于 A 矩阵在 K 维度上被切分为多个 tile，所以最终生成的 tensor 维度为 (BM, BK, K/BK)，即表示有 K/BK 个二维 tile(BM, BK)。</p> <p>作为对比，矩阵 C 在 M 维度以及 N 维度上进行切分，得到若干个 tile，每个 tile 的大小为 (BM, BN)。而后使用完整的二维坐标 <code class="language-plaintext highlighter-rouge">make_coord(blockIdx.y, blockIdx.x)</code> 取得唯一的 tile，故其生成的 tensor 维度为 (BM, BN)。</p> <p>分块之后，每个 Thread Block 分到的 tile shape 如下：</p> <ul> <li>gA(64, 16, 512)：其中，1024*8 / 16 = 512，即这是一个 tile group</li> <li>gB(64, 16, 512)：其中，1024*8 / 16 = 512，即这是一个 tile group</li> <li>gC(64, 64)</li> </ul> <h3 id="222-线程分区">2.2.2. 线程分区</h3> <p><strong>分区复制 GMEM -&gt; SMEM</strong>：</p> <p>前面已经按照 Thread Block 分块得到 tile，现在需要继续将划分细化到 Thread Block 内的每个线程。首先计算线程数量：</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// 线程块配置: (BN/TN, BM/TM) = (8, 8) = 64 线程</span>
<span class="k">constexpr</span> <span class="kt">int</span> <span class="n">num_threads</span> <span class="o">=</span> <span class="p">(</span><span class="n">BM</span> <span class="o">/</span> <span class="n">TM</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">BN</span> <span class="o">/</span> <span class="n">TN</span><span class="p">);</span>
</code></pre></div></div> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// 线程划分方法：按照 M 维度划分 A 矩阵，N 维度划分 B 矩阵</span>
<span class="n">Layout</span> <span class="n">tA_copy</span> <span class="o">=</span> <span class="n">make_layout</span><span class="p">(</span><span class="n">make_shape</span><span class="p">(</span><span class="n">Int</span><span class="o">&lt;</span><span class="n">num_threads</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">Int</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{}));</span>
<span class="n">Layout</span> <span class="n">tB_copy</span> <span class="o">=</span> <span class="n">make_layout</span><span class="p">(</span><span class="n">make_shape</span><span class="p">(</span><span class="n">Int</span><span class="o">&lt;</span><span class="n">num_threads</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">Int</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">{}));</span>

<span class="c1">// 得到本线程划分的 sub-tile</span>
<span class="n">Tensor</span> <span class="n">tAgA</span> <span class="o">=</span> <span class="n">local_partition</span><span class="p">(</span><span class="n">gA</span><span class="p">,</span> <span class="n">tA_copy</span><span class="p">,</span> <span class="n">tid</span><span class="p">);</span>  <span class="c1">// 每个线程负责的gA部分</span>
<span class="n">Tensor</span> <span class="n">tAsA</span> <span class="o">=</span> <span class="n">local_partition</span><span class="p">(</span><span class="n">sA</span><span class="p">,</span> <span class="n">tA_copy</span><span class="p">,</span> <span class="n">tid</span><span class="p">);</span>  <span class="c1">// 每个线程负责的sA部分</span>
<span class="n">Tensor</span> <span class="n">tBgB</span> <span class="o">=</span> <span class="n">local_partition</span><span class="p">(</span><span class="n">gB</span><span class="p">,</span> <span class="n">tB_copy</span><span class="p">,</span> <span class="n">tid</span><span class="p">);</span>  <span class="c1">// 每个线程负责的gB部分</span>
<span class="n">Tensor</span> <span class="n">tBsB</span> <span class="o">=</span> <span class="n">local_partition</span><span class="p">(</span><span class="n">sB</span><span class="p">,</span> <span class="n">tB_copy</span><span class="p">,</span> <span class="n">tid</span><span class="p">);</span>  <span class="c1">// 每个线程负责的sB部分</span>
</code></pre></div></div> <p>针对 tile A，只在 M 维度上进行线程划分，每个线程负责复制 <code class="language-plaintext highlighter-rouge">BM / num_threads</code> 行数据，在 K 维度上负责复制全部 K 列数据，维度信息保持，tAgA、tBgB 还是一个三维 tensor。每个线程在执行复制时，在 K 维度上每次复制 BK 列，一共需要 K / BK 次循环，才能完成 sub-tile 的加载以及 GEMM 得到最终的结果。</p> <p>矩阵 B 同理，只在 N 维度上进行线程划分。</p> <p>得到的线程分区 tensor layout 如下：</p> <ul> <li>tAgA(1, 16)：shape: (_1,_16,512), stride: (_0,1024,16384)</li> <li>tAsA(1, 16)：shape: (_1,_16), stride: (_0,64)</li> <li>tBgB(1, 16)：shape: (_1,_16,512), stride: (_0,1024,16384)</li> <li>tBsB(1, 16)：shape: (_1,_16), stride: (_0,64)</li> </ul> <p><strong>计算分区</strong>：</p> <p>每个线程复制划分，是针对矩阵 A、B 进行的。计算 C 矩阵时，需要取得 A(TM, TK) 分块、B(TN, TK) 分块、C(TM, TN)，进行线程分块的 GEMM 计算。复制时的线程分块与计算时的线程分块可以分开，因为在 GMEM -&gt; SMEM 复制之后，使用 <code class="language-plaintext highlighter-rouge">__syncthreads</code> 保证 Thread Block 的 A-tile、B-tile 都完成复制（更严谨的说，是在 GMEM -&gt; SMEM 与 sub-tile GEMM 两个步骤之间同步）。</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// 计算时的线程划分方法: (BM/TM, BN/TN) = (8, 8)</span>
<span class="n">Layout</span> <span class="n">tC</span> <span class="o">=</span> <span class="n">make_layout</span><span class="p">(</span><span class="n">make_shape</span><span class="p">(</span><span class="n">Int</span><span class="o">&lt;</span><span class="n">BM</span> <span class="o">/</span> <span class="n">TM</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">Int</span><span class="o">&lt;</span><span class="n">BN</span> <span class="o">/</span> <span class="n">TN</span><span class="o">&gt;</span><span class="p">{}));</span>

<span class="c1">// local_partition: 按线程布局分配工作</span>
<span class="c1">// Step&lt;_1, X&gt; 表示第 0 维参与分区，第 1 维不参与</span>
<span class="n">Tensor</span> <span class="n">tCsA</span> <span class="o">=</span> <span class="n">local_partition</span><span class="p">(</span><span class="n">sA</span><span class="p">,</span> <span class="n">tC</span><span class="p">,</span> <span class="n">tid</span><span class="p">,</span> <span class="n">Step</span><span class="o">&lt;</span><span class="n">_1</span><span class="p">,</span> <span class="n">X</span><span class="o">&gt;</span><span class="p">{});</span>   <span class="c1">// (TM, BK)</span>
<span class="n">Tensor</span> <span class="n">tCsB</span> <span class="o">=</span> <span class="n">local_partition</span><span class="p">(</span><span class="n">sB</span><span class="p">,</span> <span class="n">tC</span><span class="p">,</span> <span class="n">tid</span><span class="p">,</span> <span class="n">Step</span><span class="o">&lt;</span><span class="n">X</span><span class="p">,</span> <span class="n">_1</span><span class="o">&gt;</span><span class="p">{});</span>   <span class="c1">// (TN, BK)</span>
<span class="n">Tensor</span> <span class="n">tCgC</span> <span class="o">=</span> <span class="n">local_partition</span><span class="p">(</span><span class="n">gC</span><span class="p">,</span> <span class="n">tC</span><span class="p">,</span> <span class="n">tid</span><span class="p">,</span> <span class="n">Step</span><span class="o">&lt;</span><span class="n">_1</span><span class="p">,</span> <span class="n">_1</span><span class="o">&gt;</span><span class="p">{});</span>  <span class="c1">// (TM, TN)</span>
</code></pre></div></div> <p>线程分区之后，得到的每个线程的 tensor layout 如下：</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tCsA</span> <span class="n">shape</span><span class="o">:</span> <span class="p">(</span><span class="n">_8</span><span class="p">,</span><span class="n">_16</span><span class="p">),</span> <span class="n">stride</span><span class="o">:</span> <span class="p">(</span><span class="n">_8</span><span class="p">,</span><span class="n">_64</span><span class="p">)</span>
<span class="n">tCsB</span> <span class="n">shape</span><span class="o">:</span> <span class="p">(</span><span class="n">_8</span><span class="p">,</span><span class="n">_16</span><span class="p">),</span> <span class="n">stride</span><span class="o">:</span> <span class="p">(</span><span class="n">_8</span><span class="p">,</span><span class="n">_64</span><span class="p">)</span>
<span class="n">tCgC</span> <span class="n">shape</span><span class="o">:</span> <span class="p">(</span><span class="n">_8</span><span class="p">,</span><span class="n">_8</span><span class="p">),</span> <span class="n">stride</span><span class="o">:</span> <span class="p">(</span><span class="n">_8</span><span class="p">,</span><span class="mi">8192</span><span class="p">)</span>
</code></pre></div></div> <h3 id="223-slice-k-gemm">2.2.3. slice-k GEMM</h3> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// 遍历K维度</span>
<span class="k">const</span> <span class="kt">int</span> <span class="n">num_tile_k</span> <span class="o">=</span> <span class="n">K</span> <span class="o">/</span> <span class="n">BK</span><span class="p">;</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">num_tile_k</span><span class="p">;</span> <span class="n">k</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// 从全局内存复制到共享内存</span>
  <span class="n">copy</span><span class="p">(</span><span class="n">tAgA</span><span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">k</span><span class="p">),</span> <span class="n">tAsA</span><span class="p">);</span>
  <span class="n">copy</span><span class="p">(</span><span class="n">tBgB</span><span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">k</span><span class="p">),</span> <span class="n">tBsB</span><span class="p">);</span>

  <span class="n">__syncthreads</span><span class="p">();</span>  <span class="c1">// 等待所有线程完成复制</span>

  <span class="c1">// 使用 cute::gemm 执行矩阵乘法</span>
  <span class="c1">// gemm 期望: A(M,K), B(N,K), C(M,N) - B是(N,K)形式</span>
  <span class="n">gemm</span><span class="p">(</span><span class="n">tCsA</span><span class="p">,</span> <span class="n">tCsB</span><span class="p">,</span> <span class="n">tCrC</span><span class="p">);</span>  <span class="c1">// tCrC += tCsA * tCsB^T</span>

  <span class="n">__syncthreads</span><span class="p">();</span>  <span class="c1">// 等待所有线程完成计算</span>
<span class="p">}</span>
</code></pre></div></div> <p>在 tile 分区的时候，已经将 A-tile、B-tile 划分为 K/BK 个子 tile，即沿着 K 维度进行了分块。计算时，针对每一个 sub-tile 进行 GEMM，一共迭代 K / BK 次。</p> <blockquote> <p>当矩阵是列主序时（比如矩阵 A、B 是 K-major），如果 Thread Block 内的线程任务划分也按照 K-major 进行，这样得到的访问矩阵内的元素的编号也是连续的，即<strong>访存合并</strong>。</p> </blockquote> <h3 id="224-bank-conflict-计算">2.2.4. Bank Conflict 计算</h3> <p>依据 outter-partition 划分的方式：</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Layout</span> <span class="n">tC</span> <span class="o">=</span> <span class="n">make_layout</span><span class="p">(</span><span class="n">make_shape</span><span class="p">(</span><span class="n">Int</span><span class="o">&lt;</span><span class="n">BM</span> <span class="o">/</span> <span class="n">TM</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">Int</span><span class="o">&lt;</span><span class="n">BN</span> <span class="o">/</span> <span class="n">TN</span><span class="o">&gt;</span><span class="p">{}));</span>

<span class="n">Tensor</span> <span class="n">tCsA</span> <span class="o">=</span> <span class="n">local_partition</span><span class="p">(</span><span class="n">sA</span><span class="p">,</span> <span class="n">tC</span><span class="p">,</span> <span class="n">tid</span><span class="p">,</span> <span class="n">Step</span><span class="o">&lt;</span><span class="n">_1</span><span class="p">,</span> <span class="n">X</span><span class="o">&gt;</span><span class="p">{});</span>   <span class="c1">// (TM, BK)</span>
<span class="n">Tensor</span> <span class="n">tCsB</span> <span class="o">=</span> <span class="n">local_partition</span><span class="p">(</span><span class="n">sB</span><span class="p">,</span> <span class="n">tC</span><span class="p">,</span> <span class="n">tid</span><span class="p">,</span> <span class="n">Step</span><span class="o">&lt;</span><span class="n">X</span><span class="p">,</span> <span class="n">_1</span><span class="o">&gt;</span><span class="p">{});</span>   <span class="c1">// (TN, BK)</span>
</code></pre></div></div> <p>线程在 tC layout 中的二维坐标：</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tC_row = tid % 8  (M 维度方向)
tC_col = tid / 8  (N 维度方向)
</code></pre></div></div> <h4 id="2241-tcsa-访问方式及-bank-conflict-分析">2.2.4.1. tCsA 访问方式及 bank conflict 分析</h4> <p>Step&lt;_1, X&gt; 表示使用 M 维度参与分区。</p> <p>线程的 tCsA 起始行号为：</p> \[\text{row_offset}_{A} = \text{tC_row} \times \text{TM} = (\text{tid} \% 8) \times 8\] <p>线程访问 sA 的地址计算公式：</p> \[\begin{aligned} &amp; \text{addr}_{sA}[m, k] = (\text{row_offset}_{A} + m) + k \times 64 \\ &amp; m \in [0, 7], k \in [0, 15] \end{aligned}\] <p>stride=8，可以理解为每个线程占据 8 个float 类型数据，则 4 个线程之后即产生 bank conflict。</p> <p>此时，每隔 4 个线程，访问的地址会落在同一个 bank 上，并产生 bank conflict。一个 warp 内 （tid - bankId） 对应表如下：</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0 -  0,   1 -  8,   2 -  16,    3 - 24]
[4 -  0,   5 -  8,   6 -  16,    7 - 24]
[8 -  0,   9 -  8,   10 - 16,   11 - 24]
[12 - 0,   13 - 8,   14 - 16,   15 - 24]
</code></pre></div></div> <blockquote> <p>其中，由于 m = (m+1) % 8，第 8 个线程地址跳跃 64 个 float。</p> </blockquote> <p>即一个 warp 产生 4 个 4-way bank conflict。</p> <h4 id="2242-tcsb-访问方式及-bank-conflict-分析">2.2.4.2. tCsB 访问方式及 bank conflict 分析</h4> <p>Step&lt;X, _1&gt; 表示使用 N 维度参与分区。</p> <p>每个线程的 tCsB 起始行号为：</p> \[\text{row_offset}_{B} = \text{tC_col} * \text{TN} = (\text{tid} / 8) \times 8\] <p>线程访问 sB 的地址计算公式：</p> \[\begin{aligned} &amp; \text{addr}_{sB}[n, k] = (\text{row_offset}_{B} + n) + k \times 64 \\ &amp; n \in [0, 7], k \in [0, 15] \end{aligned}\] <p>此时，每 8 个线程一组，其访问地址都是同一个地址。下一组 8 个线程，其在 smemB[] 中的编号 +8。即每相邻的 8 个线程，产生一个 broadcast。对应表格如下：</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0 - 0,  1 - 0,  2 - 0,  3 - 0, 4 - 0,  5 - 0,  6 - 0,  7 - 0]
[8 - 8,  9 - 8,  10 -8,  11 -8, 12 -8,  13 -8,  14 -8,  15 -8]
</code></pre></div></div> <blockquote> <p>一个 warp 内，从第 8 个线程开始，访问编号跳转了 64 个 float。</p> </blockquote> <h4 id="2243-总结">2.2.4.3. 总结</h4> <p>发现，在当前情况下（sA 与 sB 布局相同，且划分大小相同），他们之前不一样的地方，来自于划分时，选择的维度不同：</p> <ul> <li>首先，线程被划分为两个维度，且使用这两个维度分别去划分 sA 与 sB。</li> <li>其次，由于使用了这两个维度进行划分，导致 M 维度是使用取余，N 维度是使用整除。这才是导致访问模式不同的根本原因。</li> </ul> <p>性能影响：</p> <ul> <li>tCsA 访问产生 bank conflict，影响性能。</li> <li>tCsB 访问产生 broadcast，带宽利用率低。</li> </ul> <h2 id="23-stride-理解">2.3 Stride 理解</h2> <p><code class="language-plaintext highlighter-rouge">make_stride(s0, s1)</code> 定义了沿各维度移动时的内存跳跃距离：</p> <ul> <li> <code class="language-plaintext highlighter-rouge">stride(1, M)</code> → 第0维步长=1（连续），第1维步长=M → <strong>列主序</strong> </li> <li> <code class="language-plaintext highlighter-rouge">stride(M, 1)</code> → 第0维步长=M，第1维步长=1（连续） → <strong>行主序</strong> </li> </ul> <blockquote> <p><strong>简单记忆</strong>：Stride 为 1 的维度在内存中连续。</p> </blockquote> <h2 id="24-cute-命名约定">2.4 CuTe 命名约定</h2> <p>CuTe 官方推荐的变量命名规则，便于理解代码中各 tensor 的用途和存储位置。</p> <p><strong>前缀含义</strong>：</p> <table> <thead> <tr> <th>前缀</th> <th>英文</th> <th>含义</th> </tr> </thead> <tbody> <tr> <td><code class="language-plaintext highlighter-rouge">m</code></td> <td>matrix</td> <td>完整矩阵的 tensor 视图</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">g</code></td> <td>global</td> <td>全局内存中的 tile</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">s</code></td> <td>shared</td> <td>共享内存中的 tensor</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">r</code></td> <td>register</td> <td>寄存器中的 tensor</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">t</code></td> <td>thread</td> <td>线程级别的分区/布局</td> </tr> </tbody> </table> <p><strong>后缀含义</strong>：</p> <table> <thead> <tr> <th>后缀</th> <th>含义</th> </tr> </thead> <tbody> <tr> <td><code class="language-plaintext highlighter-rouge">A</code></td> <td>矩阵 A 相关</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">B</code></td> <td>矩阵 B 相关</td> </tr> <tr> <td><code class="language-plaintext highlighter-rouge">C</code></td> <td>矩阵 C 相关</td> </tr> </tbody> </table> <p><strong>组合命名规则</strong> <code class="language-plaintext highlighter-rouge">tXyZ</code>：</p> <ul> <li> <code class="language-plaintext highlighter-rouge">t</code> = thread 级别</li> <li> <code class="language-plaintext highlighter-rouge">X</code> = 用于什么操作（A=复制A, B=复制B, C=计算C）</li> <li> <code class="language-plaintext highlighter-rouge">y</code> = 存储位置（g=global, s=shared, r=register）</li> <li> <code class="language-plaintext highlighter-rouge">Z</code> = 哪个矩阵（A, B, C）</li> </ul> <p><strong>示例</strong>：</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Tensor</span> <span class="n">mA</span> <span class="o">=</span> <span class="p">...;</span>     <span class="c1">// matrix A - 完整矩阵视图</span>
<span class="n">Tensor</span> <span class="n">gA</span> <span class="o">=</span> <span class="p">...;</span>     <span class="c1">// global A - 全局内存中的 tile</span>
<span class="n">Tensor</span> <span class="n">sA</span> <span class="o">=</span> <span class="p">...;</span>     <span class="c1">// shared A - 共享内存 tensor</span>

<span class="n">Tensor</span> <span class="n">tAgA</span> <span class="o">=</span> <span class="p">...;</span>   <span class="c1">// thread partition (for A copy) of global A</span>
<span class="n">Tensor</span> <span class="n">tAsA</span> <span class="o">=</span> <span class="p">...;</span>   <span class="c1">// thread partition (for A copy) of shared A</span>
<span class="n">Tensor</span> <span class="n">tCsA</span> <span class="o">=</span> <span class="p">...;</span>   <span class="c1">// thread partition (for C compute) of shared A</span>
<span class="n">Tensor</span> <span class="n">tCrC</span> <span class="o">=</span> <span class="p">...;</span>   <span class="c1">// thread partition (for C compute) of register C</span>
</code></pre></div></div> <blockquote> <p><strong>为什么同一个矩阵有不同的分区？</strong> 因为复制和计算时的线程分工不同。例如 <code class="language-plaintext highlighter-rouge">sA</code>： 复制时：64个线程平均分配 <code class="language-plaintext highlighter-rouge">BM×BK</code> 元素 → <code class="language-plaintext highlighter-rouge">tAsA</code> 计算时：每个线程取 <code class="language-plaintext highlighter-rouge">TM×BK</code> 子矩阵 → <code class="language-plaintext highlighter-rouge">tCsA</code></p> </blockquote> <h2 id="资料">资料</h2> <ul> <li> <a href="https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html" rel="external nofollow noopener" target="_blank">Matrix Multiplication Background User’s Guide</a>。如何计算 GEMM 的性能指标</li> <li> <a href="https://docs.nvidia.com/cutlass/latest/media/docs/cpp/cute/0x_gemm_tutorial.html" rel="external nofollow noopener" target="_blank">CuTe dense matrix-matrix multiply tutorial</a>。CuTe GEMM 官方 Document。</li> <li> <a href="https://zhuanlan.zhihu.com/p/667521327" rel="external nofollow noopener" target="_blank">cute 之 简单GEMM实现</a>：reed 知乎文章</li> <li> <a href="https://zhuanlan.zhihu.com/p/663092747" rel="external nofollow noopener" target="_blank">cute 之 MMA抽象</a>：reed 知乎文章</li> <li> <a href="https://leimao.github.io/blog/CuTe-Local-Partition/" rel="external nofollow noopener" target="_blank">CuTe Local Partition</a>：Mao Lei博客</li> <li> <a href="https://leimao.github.io/article/CUDA-Matrix-Multiplication-Optimization/" rel="external nofollow noopener" target="_blank">CUDA Matrix Multiplication Optimization</a>：Mao Lei博客，GEMM优化步骤全解析</li> <li> <a href="https://research.colfax-intl.com/category/papers/tutorials/" rel="external nofollow noopener" target="_blank">Colfax Research Cute Tutorial</a>：Colfax Research Cute Tutorial</li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/al-folio-local-deploy-ubuntu2404/">al-folio 本地部署记录（Ubuntu 24.04）</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/C++-Traits/">C++ Traits</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/%E9%81%93%E6%A0%BC%E6%8B%89%E6%96%AF-%E6%99%AE%E5%85%8B%E7%AE%97%E6%B3%95/">道格拉斯-普克算法(Douglas–Peucker algorithm)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/CMake%E6%94%AF%E6%8C%81%E5%BA%93/">CMake支持库收集</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/QGC%E9%A3%9E%E8%A1%8C%E5%89%8D%E6%A3%80%E6%9F%A5/">QGC代码架构解析：飞行前检查（起飞条件）</a> </li> </div> </div> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Roderick Huang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?v=c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>