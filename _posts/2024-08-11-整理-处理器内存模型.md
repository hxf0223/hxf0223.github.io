---
layout: post
title: 整理：内存一致模型
date: 2024-08-11 +0800 # 2022-01-01 13:14:15 +0800 只写日期也行；不写秒也行；这样也行 2022-03-09T00:55:42+08:00
categories: [CPU]
tags: [Cpp, CPU]

# 以下默认false
math: true
mermaid: true
# pin: true
toc:
  sidebar: right
---

## 1. CPU Cache 内部结构

![CPU structure](/assets/images/cpu/memory_order_20240811/cpu_structure.png)

一个`core`内部结构：

- `cache`
- `store buffer`
- `invalidate queue`

结构如下图所示：

![CPU cache structure](/assets/images/cpu/memory_order_20240811/core_structure_cache_store_buffer_inv_queue2.png)

### 1.1. `Cahce`一致性协议 `MESI`

`MESI`是`CPU`内部多个`core`同步通讯协议，保证多个`core`中的`cache`的数据一致性。`MESI`这四个字母分别代表了每一个`cache line`可能处于的四种状态：`Modified`、`Exclusive`、`Shared` 和 `Invalid`。

通过给`cache line`设置状态位，以及`CPU core`（也可能有内存控制器参与）之间的消息同步逻辑，让多个`core`中的`cache`数据保持一致性。

在没有`store buffer`, `invalidate queue`之前，`MESI`可以保证不需要`memory fence`指令也可以保证数据的一致性。

### 1.2. `False sharing`

`False sharing`的原因是两个`CPU`访问的变量，在内存中的位置，同时落入一个`cache line`范围内，根据`MESI`协议，一个`CPU`写操作，将导致另一个`CPU`的读写操作之前，需要进行`memory`及两个`CPU`的`cache line`同步操作。通常发生在两个线程操作同一个数据结构体的时候。

![false sharing](/assets/images/cpu/memory_order_20240811/MESI-false-sharing.svg)

```c++
#define CACHE_ALIGN_SIZE 64
#define CACHE_ALIGNED __attribute__((aligned(CACHE_ALIGN_SIZE)))

struct aligned_value {
  int64_t val;
} CACHE_ALIGNED; // Note: aligning the struct to a cache line size
aligned_value aligned_data[2] CACHE_ALIGNED;

// sizeof(aligned_value) == 128
```

### 1.3. 现代`CPU`上`MESI`的局限

由于`MESI`同步协议导致处理器之间同步的代价很高，现代处理器再每个`core`里面增加两个异步队列: `store buffer`和`invalidate queue`来减少`CPU`的空闲等待。这两个异步队列，导致`MESI`协议失效。

- `store buffer`: `CPU`将`write/store`操作数据放入`store buffer`，`cache`负责`flush`操作。
- `invalidate queue`: `cache`收到`Invalidate`消息，不是马上执行，而是放入`invalidate queue`，等待`CPU`空闲时，再执行。

其原因是：针对发起方`CPU`，其认为自己的`store` / `invalidate`操作已经完成，但是由于数据/消息是放在`store buffer` / `invalidate queue`中，所以可能还没来得及被其他`CPU`看到，导致数据不一致。

其中的一个解决办法是：发起方的`store buffer`被清空，接收方的`invalieate queue`被处理掉。在此之后，`MESI`协议可以正常工作。

### 1.4. 补充：CPU指令流水线

```text
1. Fetch         <-- ✅ 顺序取指，从指令缓存中取出下一条指令
2. Decode        <-- 顺序解码，分析操作数和目的寄存器
3. Rename        <-- 寄存器重命名
4. Dispatch      <-- 投递到调度窗口，等待执行条件满足
5. Execute       <-- ✅ 乱序执行（由调度器决定），实际在执行单元上运行指令
6. Writeback     <-- 写结果到 ROB
7. Commit        <-- ✅ 按程序顺序提交（retire），更新寄存器状态或进行内存写入
```

## 2. `memory barrier`

### 2.1. 概念及理论

- 同步点：针对同一个`原子变量`的`load`操作与`store`操作，分别构成一个`同步点`。其概念有三要素：(1)：`load`/`store`操作，(2)：针对同一个原子变量，(3)：以及在不同线程中；
- `synchronize-with` 关系，该概念包含两个含义：(1)：同一个同步点，(2)：读取的值是另一个同步点写入的值；
- `happens-before` 关系；

`memory fence`定义的是同步点操作，即分别在`store`一方插入一个`write barrier`指令，在`load`一方插入一个`read barrier`指令。

因此，`memory barrier`需要成对出现，否则达不到同步效果。

### 2.2. 详细解释

由于多核处理器 `CPU` 之间独立的`L1/L2 cache`，会出现`cache line`不一致的问题，为了解决这个问题，有相关协议模型，比如 `MESI` 协议来保证 `cache` 数据一致，同时由于 `CPU` 对 `MESI` 进行的异步优化，对写和读分别引入了「`store buffer`」和「`invalid queue`」，很可能导致后面的指令查不到前面指令的执行结果（各个指令的执行顺序非代码执行顺序），这种现象很多时候被称作「`CPU乱序执行`」。

为了解决乱序问题（也可以理解为可见性问题，修改完没有及时同步到其他的CPU），又引出了「`内存屏障`」的概念；内存屏障可以分为三种类型：`写屏障`，`读屏障`以及`全能屏障（包含了读写屏障）`，屏障可以简单理解为：在操作数据的时候，往数据插入一条`特殊的指令`。只要遇到这条指令，那前面的操作都得「完成」。

1. `写屏障`指令(`write barrier`, or `sfence`)，等待之前的写操作完成，并把该指令「之前」存在于「`store Buffer`」中的所有写指令刷入`cache`。就可以让`CPU`修改的数据马上暴露给其他`CPU`(`MESI`)，达到「写操作」可见性的效果。

2. `读屏障`指令(`read barrier`, or `lfence`)，会把该指令「之前」存在于「`invalid queue`」中的所有的指令都处理掉。通过这种方式就可以确保当前CPU的缓存状态是准确的，达到「读操作」一定是读取最新的效果。

由于不同CPU架构的缓存体系不一样、缓存一致性协议不一样、重排序的策略不一样、所提供的内存屏障指令也有差异，所以一些语言c++/java/go/rust 都有实现自己的内存模型, 比如golang大牛`Russ Cox`写的内存模型系列文章 [Memory Models](https://research.swtch.com/mm) 值得深入了解。

### 2.3. `x86`上面的`fence`实操演示

`ARM`架构CPU有`Store Buffer`、`Invalidate Queue`，是一个松散内存一致性模型。`x86`架构只有`Store Buffer`，是一个强内存一致性模型。

在`x86`架构下，对`StoreLoad`操作进行重排(乱序)。其余几种保持顺序：`StoreStore`, `LoadLoad`, `LoadStore`，即不需要设置`fence`指令也可以保持`CPU`之间的内存一致性。

禁止编译器重排：

```cpp
X = 1;
asm volatile("" ::: "memory"); // Prevent compiler reordering
r1 = Y;
```

禁止编译器及`CPU`重排：

```cpp
X = 1;
asm volatile("mfence" ::: "memory"); // Prevent compiler and CPU reordering
r1 = Y;
```

详细知识参考：

- [CPU 缓存一致性与内存屏障](https://wingsxdu.com/posts/note/cpu-cache-and-memory-barriers/)
- [Cache一致性和内存一致性](https://wudaijun.com/2019/04/cache-coherence-and-memory-consistency/)
- [Acquire and Release Fences](https://preshing.com/20130922/acquire-and-release-fences/)
- [從硬體觀點了解 memory barrier 的實作和效果](https://medium.com/fcamels-notes/%E5%BE%9E%E7%A1%AC%E9%AB%94%E8%A7%80%E9%BB%9E%E4%BA%86%E8%A7%A3-memry-barrier-%E7%9A%84%E5%AF%A6%E4%BD%9C%E5%92%8C%E6%95%88%E6%9E%9C-416ff0a64fc1)
- [CPU架构和MESI缓存一致性->内存模型一致性->内存屏障和原子操作->内存序->C++内存序](https://www.cnblogs.com/yiwanfengweng/articles/18657841)

## 3. C++11 内存一致性模型定义

| 内存序          | 插入屏障  | 特点                                                                                        |
| --------------- | --------- | ------------------------------------------------------------------------------------------- |
| relaxed         | ❌ 无     | 只保证原子性，不保证顺序                                                                    |
| acquire         | ✅ 读屏障 | LFENCE 指令等待之前的 load 指令执行完成，所以后续 load 指令不能在 LFENCE 之前执行           |
| release         | ✅ 写屏障 | SFENCE 之前的 store 指令在 SFENCE 之前完成，并且保证其可见性早于在 SFENCE 之后的 store 指令 |
| acquire-release | ✅        | 两者都有 双向有序                                                                           |
| seq_cst         | ✅ 全屏障 | 全局顺序一致性                                                                              |

> 参见：<https://www.felixcloutier.com/x86/sfence>，以及<https://www.felixcloutier.com/x86/lfence>。

### 3.1. release/acquire 如何实现局部同步

```cpp
void release_store(atomic<int>* ptr, int val) {
    // 1. 先刷新 Store Buffer（之前的所有store）
    drain_store_buffer();

    // 2. 执行本次 store
    *ptr = val;  // 这个写入也会进入store buffer

    // 3. 发出刷新本次store的指令（架构相关）
    // x86: 自动（TSO模型）
    // ARM: DMB ISHST (Store-Store barrier)
}

int acquire_load(atomic<int>* ptr) {
    // 1. 执行 load
    int val = *ptr;

    // 2. 处理 Invalidate Queue 中所有待处理的失效消息
    drain_invalidate_queue();

    // 3. 防止后续的 load/store 被重排到此之前
    // x86: 自动（不会重排 load-load, load-store）
    // ARM: DMB ISHLD (Load-Load/Store barrier)

    return val;
}
```

### 3.2. memory_order_seq_cst 如何实现全局同步

```cpp
// x86-64 的实现示例
void seq_cst_store(atomic<int>* ptr, int val) {
    // 1. 完全刷新 Store Buffer（所有待写入的数据）
    __asm__ volatile("mfence" : :: "memory");

    // 2. 使用带 LOCK 前缀的指令 或 XCHG
    // LOCK 前缀会：
    //   - 锁定缓存行（或总线）
    //   - 立即刷新该地址的 store buffer
    //   - 强制其他CPU立即处理 invalidate queue
    __asm__ volatile(
        "lock; xchgl %0, %1"
        : "=r"(val)
        : "m"(*ptr), "0"(val)
        : "memory"
    );

    // 或者
    *ptr = val;
    __asm__ volatile("mfence" ::: "memory");
}

void seq_cst_load(atomic<int>* ptr) {
    // 1. 先屏障
    __asm__ volatile("mfence" :::  "memory");

    // 2. Load 操作
    int val = *ptr;

    // 3. 强制处理 invalidate queue
    // x86 的 mfence 会等待所有失效消息被处理
    __asm__ volatile("mfence" :::  "memory");

    return val;
}
```

关键差异：

```text
普通的 Store Buffer 刷新（Release）：
-----------------------------------------
CPU 0: [Store Buffer] → L1 Cache
                         ↓
                    发送 Invalidate
                         ↓
CPU 1:              [Invalidate Queue] (异步处理)


Seq_cst 的强制同步：
-----------------------------------------
CPU 0: mfence/dmb ish
         ↓
       等待所有 Store Buffer 完全刷新
         ↓
       等待所有 Invalidate 被确认
         ↓
       执行 store (with LOCK 或类似机制)
         ↓
       强制发送 Invalidate + 等待ACK
         ↓
CPU 1:  必须立即处理 Invalidate Queue
         ↓
       在下一个 mfence 时必须等待处理完成
```

`MESI`协议层：

```text
CPU0:  seq_cst_store(x, 1)
      |
      +--> mfence (确保之前所有操作完成)
      +--> store x=1
      +--> mfence (确保之后所有操作在此之后)
      +--> 触发缓存一致性协议，广播到所有CPU

CPU1, CPU2, CPU3:
      +--> 接收到缓存失效消息
      +--> 后续的seq_cst_load必须等待屏障完成
      +--> 从内存/共享缓存读取最新值
```

### 3.3. 示例代码

```cpp
#include <thread>
#include <atomic>
#include <cassert>
#include <string>

std::atomic<std::string*> ptr{nullptr};
int data{42};

void producer() {
  std::string* p  = new std::string("Hello");
  data = 42;
  ptr.store(p, std::memory_order_release);
}

void consumer() {
  std::string* p2;
  while (nullptr == (p2 = ptr.load(std::memory_order_acquire)));
  assert(*p2 == "Hello"); // never fires
  assert(data == 42); // never fires
}

int main() {
  std::thread t1(producer);
  std::thread t2(consumer);
  t1.join(); t2.join();
  return 0;
}
```

## 参考资料

- [内存模型](https://bi-an.github.io/blog/2025/08/01/concurrency/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/)
- [谈谈 C++ 中的内存顺序 (Memory Order)](https://luyuhuang.tech/2022/06/25/cpp-memory-order.html)
- [程序员的自我修养（⑫）：C++ 的内存顺序·中](https://liam.page/2021/12/11/memory-order-cpp-02/)

## 更多资料

- [C++ Concurrency In Action 2ed 中文翻译](https://simonhancrew.github.io/CppConcurencyInAction/)
- [C++ Concurrency in Action, 2nd Edition](/assets/pdf/cpu/C++%20Concurrency%20in%20Action,%202nd%20Edition.pdf)
- [现代CPU性能分析与优化 -- 现代CPU设计](https://weedge.github.io/perf-book-cn/zh/chapters/3-CPU-Microarchitecture/3-8_Modern_CPU_design_cn.html)
- [现代CPU性能分析与优化 -- README](https://weedge.github.io/perf-book-cn/zh/)
- [现代CPU性能分析与优化 -- pdf](/assets/pdf/cpu/perf-book-cn.pdf)
